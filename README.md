# Асинхронный парсер документации Python

## Описание

- собирает ссылки на статьи о нововведениях в Python, переходит по ним и
забирает информацию о номере, статусе и количестве статей;
- собирает данные о документах PEP, считает их количество в каждом статусе

## Подготовка и запуск проекта

Склонировать репозиторий на локальную машину:
```
git clone https://github.com/Hlompy/scrapy_parser_pep.git
```
Установить и активировать виртуальное окружение
```
python -m venv venv
source venv/bin/activate
```
Установить требуемые зависимости
```
pip install -r requirements.txt
```
Далее запуск скрипта командой
```
scrapy crawl pep
```
## Результат работы скрипта

В ходе работы скрипта в папке results будет создано 2 файла

- pep - куда будет собраны все PEP в виде csv файла в формате <номер,имя,статус>

- status summary - куда будет сгенерирована таблица с количеством PEP находящимся
в каждом статусе

## Технологии
В ходе разработки были использованы

- Scrappy
## Автор

Крюков Георгий
